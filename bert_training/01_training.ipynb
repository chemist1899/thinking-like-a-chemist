{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install tensorflowÍ\n",
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "from importlib import reload\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m wandb login $WANDB_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_count = '1m'\n",
    "model_name = f'd-bert_{samples_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def read_data():\n",
    "    # data = pd.read_csv(f'out-{samples_count}.csv')\n",
    "    data1 = pd.read_csv(f'preprocessed_1_500k_with_descriptors.csv')\n",
    "    data2 = pd.read_csv(f'preprocessed_2_500k_with_descriptors.csv')\n",
    "    data = pd.concat([data1, data2], ignore_index=True)\n",
    "    import ast\n",
    "\n",
    "    def string_to_array(input_string):\n",
    "        try:\n",
    "            # Use ast.literal_eval to safely evaluate the string as a Python literal\n",
    "            result = ast.literal_eval(input_string)\n",
    "            return result\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Error parsing the string: {e}\")\n",
    "            return None\n",
    "    data['descriptors'] = data['descriptors'].progress_apply(lambda x: string_to_array(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [2],\n",
       "  [1, 0, 0, 0],\n",
       "  [5],\n",
       "  [1],\n",
       "  [3],\n",
       "  [2],\n",
       "  [0],\n",
       "  [0]],\n",
       " [[1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [2],\n",
       "  [0, 1, 0, 0],\n",
       "  [3],\n",
       "  [1],\n",
       "  [3],\n",
       "  [2],\n",
       "  [0],\n",
       "  [0]],\n",
       " [[0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1],\n",
       "  [0, 0, 0, 0],\n",
       "  [2],\n",
       "  [0],\n",
       "  [3],\n",
       "  [2],\n",
       "  [0],\n",
       "  [0]],\n",
       " [[17, 20, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [21],\n",
       "  [18, 1, 0, 6],\n",
       "  [45],\n",
       "  [691],\n",
       "  [3],\n",
       "  [3],\n",
       "  [18],\n",
       "  [5]],\n",
       " '$',\n",
       " [[2, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [4],\n",
       "  [2, 1, 0, 0],\n",
       "  [7],\n",
       "  [10],\n",
       "  [3],\n",
       "  [2],\n",
       "  [0],\n",
       "  [0]],\n",
       " [[1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [3],\n",
       "  [1, 1, 0, 0],\n",
       "  [4],\n",
       "  [4],\n",
       "  [3],\n",
       "  [2],\n",
       "  [0],\n",
       "  [0]],\n",
       " [[17, 20, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [22],\n",
       "  [19, 1, 0, 6],\n",
       "  [46],\n",
       "  [788],\n",
       "  [3],\n",
       "  [3],\n",
       "  [18],\n",
       "  [5]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['descriptors'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shifter as sh\n",
    "reload(sh)\n",
    "\n",
    "shifter = sh.Shifter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for descriptors_of_substructures in data['descriptors']:\n",
    "    shifter.shift(descriptors_of_substructures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7834"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum = 0\n",
    "for mol in data['descriptors']:\n",
    "    for substr in mol:\n",
    "        if substr == '$':\n",
    "            continue\n",
    "        for descriptor in substr:\n",
    "            for i in descriptor:\n",
    "                maximum = max(maximum, i)\n",
    "maximum # vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizer as tokenizer\n",
    "reload(tokenizer)\n",
    "# tokenized_descriptors = tokenizer.tokenize(data['descriptors'], max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm(tensor):\n",
    "    print(tensor)\n",
    "    # create random array of floats with equal dims to tensor\n",
    "    rand = torch.rand(tensor.shape)\n",
    "    # mask random 15% where token is not 0 <s>, 1 <pad>, or 2 <s/>\n",
    "    mask_arr = (rand < .15) * (tensor != 0) * (tensor != 1) * (tensor != 2)\n",
    "    # loop through each row in tensor (cannot do in parallel)\n",
    "    for i in range(tensor.shape[0]):\n",
    "        # get indices of mask positions from mask array\n",
    "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        # mask tensor\n",
    "        tensor[i, selection] = 4\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_descriptors(data, start, end = -1):\n",
    "    input_ids = []\n",
    "    mask = []\n",
    "    labels = []\n",
    "    sample = tokenizer.tokenize(data['descriptors'][start:end], max_length=512)\n",
    "    \n",
    "    labels.append(torch.tensor(sample['input_ids']))\n",
    "    mask.append(torch.tensor(sample['attention_mask']))\n",
    "    input_ids.append(mlm(labels[-1].detach().clone())) # mask ~15% of tokens to create inputs\n",
    "    \n",
    "    input_ids = torch.cat(input_ids)\n",
    "    mask = torch.cat(mask)\n",
    "    \n",
    "    labels = torch.cat(labels)\n",
    "    return input_ids, mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4993.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    7,  110,  207,  306,  406,  506,  606,  706,  806,  906, 1006,\n",
      "         1106, 1208, 1257, 1556, 1856, 2156, 2461, 2757, 7759, 7766, 7773, 7823,\n",
      "            3,    7,  108,  207,  306,  406,  506,  606,  706,  806,  906, 1006,\n",
      "         1106, 1208, 1256, 1557, 1856, 2156, 2459, 2757, 7759, 7766, 7773, 7823,\n",
      "            3,    6,  108,  207,  306,  406,  506,  606,  706,  806,  906, 1006,\n",
      "         1106, 1207, 1256, 1556, 1856, 2156, 2458, 2756, 7759, 7766, 7773, 7823,\n",
      "            3,   23,  126,  209,  307,  406,  506,  606,  706,  806,  906, 1006,\n",
      "         1106, 1227, 1274, 1557, 1856, 2162, 2501, 3447, 7759, 7767, 7791, 7828,\n",
      "            3,    5,    8,  110,  208,  306,  406,  506,  606,  706,  806,  906,\n",
      "         1006, 1106, 1210, 1258, 1557, 1856, 2156, 2463, 2766, 7759, 7766, 7773,\n",
      "         7823,    3,    7,  108,  208,  306,  406,  506,  606,  706,  806,  906,\n",
      "         1006, 1106, 1209, 1257, 1557, 1856, 2156, 2460, 2760, 7759, 7766, 7773,\n",
      "         7823,    3,   23,  126,  210,  307,  406,  506,  606,  706,  806,  906,\n",
      "         1006, 1106, 1228, 1275, 1557, 1856, 2162, 2502, 3544, 7759, 7767, 7791,\n",
      "         7828,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids, mask, labels = tokenize_descriptors(data, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 763016/763016 [00:47<00:00, 15918.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   7, 110,  ...,   1,   1,   1],\n",
      "        [  0,  11, 113,  ...,   1,   1,   1],\n",
      "        [  0,  14, 116,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  0,   7, 108,  ...,   1,   1,   1],\n",
      "        [  0,  14, 115,  ...,   1,   1,   1],\n",
      "        [  0,   9, 114,  ...,   1,   1,   1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95377/95377 [00:05<00:00, 17279.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,  16, 124,  ...,   1,   1,   1],\n",
      "        [  0,   7, 110,  ...,   1,   1,   1],\n",
      "        [  0,   7, 110,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  0,   7, 107,  ...,   1,   1,   1],\n",
      "        [  0,  11, 113,  ...,   1,   1,   1],\n",
      "        [  0,  13, 121,  ...,   1,   1,   1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95377/95377 [00:05<00:00, 17352.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,  14, 114,  ...,   1,   1,   1],\n",
      "        [  0,   8, 110,  ...,   1,   1,   1],\n",
      "        [  0,  13, 113,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  0,  14, 114,  ...,   1,   1,   1],\n",
      "        [  0,  19, 119,  ...,   1,   1,   1],\n",
      "        [  0,   8, 112,  ...,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_mask, train_labels = tokenize_descriptors(data, 0, int(0.8 * len(data)))\n",
    "validation_input_ids, validation_mask, validation_labels = tokenize_descriptors(data, int(0.8 * len(data)), int(0.9 * len(data)))\n",
    "test_input_ids, test_mask, test_labels = tokenize_descriptors(data, int(0.9 * len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([763016, 512])\n",
      "torch.Size([95377, 512])\n",
      "torch.Size([95377, 512])\n"
     ]
    }
   ],
   "source": [
    "print(train_input_ids.shape)\n",
    "print(validation_input_ids.shape)\n",
    "print(validation_input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    7,  110,  207,  306,  406,  506,  606,  706,  806,  906, 1006,\n",
       "        1106, 1208, 1257, 1556, 1856, 2156, 2461, 2757, 7759, 7766, 7773, 7823,\n",
       "           3,    7,  108,  207,  306,  406,  506,  606,  706,  806,  906, 1006,\n",
       "        1106, 1208, 1256, 1557, 1856, 2156, 2459, 2757, 7759, 7766, 7773, 7823,\n",
       "           3,    6,  108,  207,  306,  406,  506,  606,  706,  806,  906, 1006,\n",
       "        1106, 1207, 1256, 1556, 1856, 2156, 2458, 2756, 7759, 7766, 7773, 7823,\n",
       "           3,   23,  126,  209,  307,  406,  506,  606,  706,  806,  906, 1006,\n",
       "        1106, 1227, 1274, 1557, 1856, 2162, 2501, 3447, 7759, 7767, 7791, 7828,\n",
       "           3,    5,    8,  110,  208,  306,  406,  506,  606,  706,  806,  906,\n",
       "        1006, 1106, 1210, 1258, 1557, 1856, 2156, 2463, 2766, 7759, 7766, 7773,\n",
       "        7823,    3,    7,  108,  208,  306,  406,  506,  606,  706,  806,  906,\n",
       "        1006, 1106, 1209, 1257, 1557, 1856, 2156, 2460, 2760, 7759, 7766, 7773,\n",
       "        7823,    3,   23,  126,  210,  307,  406,  506,  606,  706,  806,  906,\n",
       "        1006, 1106, 1228, 1275, 1557, 1856, 2162, 2502, 3544, 7759, 7767, 7791,\n",
       "        7828,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(input_ids, 'preprocessed_tensors/input_ids.pt')\n",
    "# torch.save(mask, 'preprocessed_tensors/attention_mask.pt')\n",
    "# torch.save(labels, 'preprocessed_tensors/labels.pt')\n",
    "\n",
    "# del input_ids, mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.load('preprocessed_tensors/input_ids.pt')\n",
    "# mask = torch.load('preprocessed_tensors/attention_mask.pt')\n",
    "# labels = torch.load('preprocessed_tensors/labels.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset({'input_ids': train_input_ids, 'attention_mask': train_mask, 'labels': train_labels})\n",
    "validation_dataset = Dataset({'input_ids': validation_input_ids, 'attention_mask': validation_mask, 'labels': validation_labels})\n",
    "test_dataset = Dataset({'input_ids': test_input_ids, 'attention_mask': test_mask, 'labels': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And move onto building our model, we first need to create a RoBERTa config object, which will describe which features we want to initialize our RoBERTa model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=maximum + 1,\n",
    "    max_position_embeddings=514,\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import and initialize a RoBERTa model with a language modeling head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we move onto training. First we setup GPU/CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(7835, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=7835, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda', index=5) if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"bert_transformer\",\n",
    "    name=f\"RobertaForMLM on molecular descriptors training ({samples_count})\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move onto the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "epochs = 2\n",
    "step = 0\n",
    "\n",
    "validation_iterator = iter(validation_loader)\n",
    "for epoch in range(epochs):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        true_labels = batch['labels'].numpy().flatten()\n",
    "        pred_labels = torch.nn.functional.softmax(logits, dim=1).argmax(axis=-1).cpu().detach().numpy().flatten()\n",
    "\n",
    "        # write down loss and metrics\n",
    "        wandb.log({\"loss/train\": loss}, step=step)\n",
    "        wandb.log({\"accuracy/train\": accuracy_score(true_labels, pred_labels)}, step=step)\n",
    "        wandb.log({\"f1/train\": f1_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "        wandb.log({\"precision/train\": precision_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "        wandb.log({\"recall/train\": recall_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                validation_batch = next(validation_iterator)\n",
    "            except StopIteration:\n",
    "                validation_dataset = Dataset({'input_ids': validation_input_ids, 'attention_mask': validation_mask, 'labels': validation_labels})\n",
    "                validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "                validation_iterator = iter(validation_loader)\n",
    "                \n",
    "                validation_batch = next(validation_iterator)\n",
    "            \n",
    "            input_ids = validation_batch['input_ids'].to(device)\n",
    "            attention_mask = validation_batch['attention_mask'].to(device)\n",
    "            labels = validation_batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            true_labels = validation_batch['labels'].numpy().flatten()\n",
    "            pred_labels = torch.nn.functional.softmax(logits, dim=1).argmax(axis=-1).cpu().detach().numpy().flatten()\n",
    "    \n",
    "            # write down loss and metrics\n",
    "            wandb.log({\"loss/validation\": loss}, step=step)\n",
    "            wandb.log({\"accuracy/validation\": accuracy_score(true_labels, pred_labels)}, step=step)\n",
    "            wandb.log({\"f1/validation\": f1_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "            wandb.log({\"precision/validation\": precision_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "            wandb.log({\"recall/validation\": recall_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "            \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        step += len(batch['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"bert_transformer\",\n",
    "    name=f\"RobertaForMLM on molecular descriptors testing ({samples_count})\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        true_labels = batch['labels'].numpy().flatten()\n",
    "        pred_labels = torch.nn.functional.softmax(logits, dim=1).argmax(axis=-1).cpu().detach().numpy().flatten()\n",
    "\n",
    "        # write down loss and metrics\n",
    "        wandb.log({\"loss/test\": loss}, step=step)\n",
    "        wandb.log({\"accuracy/test\": accuracy_score(true_labels, pred_labels)}, step=step)\n",
    "        wandb.log({\"f1/test\": f1_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "        wandb.log({\"precision/test\": precision_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "        wandb.log({\"recall/test\": recall_score(true_labels, pred_labels, average='micro')}, step=step)\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        step += len(batch)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device('cuda', index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

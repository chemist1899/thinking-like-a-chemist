{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f265e-e433-48e9-a783-950e8b12260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3494b-0296-4bb8-9b07-48a55533413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.require(\"service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53265f1-214e-4d58-814f-6f7c7b05f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m wandb login $WANDB_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d70ee9-b6f5-415a-b98e-a6dc92cd6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "apex_support = False\n",
    "try:\n",
    "    sys.path.append('./apex')\n",
    "    from apex import amp\n",
    "\n",
    "    apex_support = True\n",
    "except:\n",
    "    print(\"Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\")\n",
    "    apex_support = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d91b4-c4dc-4dba-a04c-e786601aab87",
   "metadata": {},
   "source": [
    "### Upload config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4478096-04a8-4fe1-b1b9-8a8720750818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config = yaml.load(open(\"config-graphormer.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b16779-4235-42fe-9091-531e93496fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['num_workers'] = 1\n",
    "print('batch_size =', config['batch_size'])\n",
    "batch_size = config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa6fa0-9b19-4665-81b8-b122a0c18ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('running on device:', config['gpu'])\n",
    "device = torch.device(config['gpu']) if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d265d-3a4d-4ec1-b616-18805240e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_config_file(config, log_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    with open(os.path.join(log_dir, 'config.yml'), 'w') as outfile:\n",
    "        yaml.dump(config, outfile, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d58c5-eb7a-4420-b0db-f743e2167213",
   "metadata": {},
   "source": [
    "### Upload and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5561e6-2477-4ead-9fae-91cae781bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"preprocessed_10m_with_descriptors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63571013-4600-4c29-87ae-00b8429d7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd0143-4bb2-429e-b4e9-229aaf9daddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "tqdm.pandas()\n",
    "\n",
    "def string_to_array(input_string):\n",
    "    try:\n",
    "        # Use ast.literal_eval to safely evaluate the string as a Python literal\n",
    "        result = ast.literal_eval(input_string)\n",
    "        return result\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Error parsing the string: {e}\")\n",
    "        return None\n",
    "\n",
    "dataframe['descriptors'] = dataframe['descriptors'].progress_apply(lambda s: string_to_array(s))\n",
    "dataframe = dataframe.rename(columns={'smiles': 'Smiles'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae64520-4a9c-453f-949a-737bbd58bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "# drop bad molecules\n",
    "dropping = []\n",
    "for i in tqdm(range(len(dataframe['Smiles']))):\n",
    "    mol = Chem.MolFromSmiles(dataframe['Smiles'].iloc[i])\n",
    "    if mol is None:\n",
    "        dropping.append(i)\n",
    "        continue\n",
    "    \n",
    "    if mol.GetNumAtoms() < 2:\n",
    "        dropping.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb1370-13e9-4505-88da-b216213a873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(dropping)\n",
    "dataframe.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e904d-a6dc-4369-a9b9-59e7817bdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287894eb-5d8b-4d23-ab1c-9d3a63a35b8c",
   "metadata": {},
   "source": [
    "### Create Molecule Dataset\n",
    "##### It will generate torch_geometric.data.Data objects for both bert and GIN/GCN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd666e-fc9b-426f-aade-adebf312b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shifter as sh\n",
    "import tokenizer as tokenizer\n",
    "\n",
    "shifter = sh.Shifter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61aaf7e-b46e-42f0-8981-67d2006f7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "ATOM_LIST = list(range(1,119))\n",
    "CHIRALITY_LIST = [\n",
    "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "    Chem.rdchem.ChiralType.CHI_OTHER\n",
    "]\n",
    "BOND_LIST = [\n",
    "    Chem.rdchem.BondType.SINGLE, \n",
    "    Chem.rdchem.BondType.DOUBLE, \n",
    "    Chem.rdchem.BondType.TRIPLE, \n",
    "    Chem.rdchem.BondType.AROMATIC\n",
    "]\n",
    "BONDDIR_LIST = [\n",
    "    Chem.rdchem.BondDir.NONE,\n",
    "    Chem.rdchem.BondDir.ENDUPRIGHT,\n",
    "    Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b4fd8-4b62-40e4-8d17-583f2c68e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from torch_geometric.data import Data, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eadbf35-57e6-4ff4-9a36-883970fb8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339ed50-d66c-4b3c-bbc9-d7d284918b88",
   "metadata": {},
   "source": [
    "# Graphormer collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0654c00-0422-471e-9c5f-a64bb73c8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import is_cython_available\n",
    "if is_cython_available():\n",
    "\n",
    "    import pyximport\n",
    "\n",
    "    pyximport.install(setup_args={\"include_dirs\": np.get_include()})\n",
    "    \n",
    "    from transformers.models.graphormer import algos_graphormer as algos_graphormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac996bb-f7c3-4b94-ac4e-8c574821a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Mapping\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers.utils import is_cython_available, requires_backends\n",
    "\n",
    "\n",
    "if is_cython_available():\n",
    "    import pyximport\n",
    "\n",
    "    pyximport.install(setup_args={\"include_dirs\": np.get_include()})\n",
    "    import sys\n",
    "    sys.path.append('algos_graphormer.so')\n",
    "    import algos_graphormer\n",
    "\n",
    "\n",
    "def convert_to_single_emb(x, offset: int = 512):\n",
    "    feature_num = x.shape[1] if len(x.shape) > 1 else 1\n",
    "    feature_offset = 1 + np.arange(0, feature_num * offset, offset, dtype=np.int64)\n",
    "    x = x + feature_offset\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_item(item, keep_features=True):\n",
    "    requires_backends(preprocess_item, [\"cython\"])\n",
    "\n",
    "    if keep_features and \"edge_attr\" in item.keys():  # edge_attr\n",
    "        edge_attr = np.asarray(item[\"edge_attr\"], dtype=np.int64)\n",
    "    else:\n",
    "        edge_attr = np.ones((len(item[\"edge_index\"][0]), 1), dtype=np.int64)  # same embedding for all\n",
    "\n",
    "    if keep_features and \"node_feat\" in item.keys():  # input_nodes\n",
    "        node_feature = np.asarray(item[\"node_feat\"], dtype=np.int64)\n",
    "    else:\n",
    "        node_feature = np.ones((item[\"num_nodes\"], 1), dtype=np.int64)  # same embedding for all\n",
    "\n",
    "    edge_index = np.asarray(item[\"edge_index\"], dtype=np.int64)\n",
    "\n",
    "    input_nodes = convert_to_single_emb(node_feature) + 1\n",
    "    num_nodes = item[\"num_nodes\"]\n",
    "\n",
    "    if len(edge_attr.shape) == 1:\n",
    "        edge_attr = edge_attr[:, None]\n",
    "    attn_edge_type = np.zeros([num_nodes, num_nodes, edge_attr.shape[-1]], dtype=np.int64)\n",
    "    attn_edge_type[edge_index[0], edge_index[1]] = convert_to_single_emb(edge_attr) + 1\n",
    "\n",
    "    # node adj matrix [num_nodes, num_nodes] bool\n",
    "    adj = np.zeros([num_nodes, num_nodes], dtype=bool)\n",
    "    adj[edge_index[0], edge_index[1]] = True\n",
    "\n",
    "    shortest_path_result, path = algos_graphormer.floyd_warshall(adj)\n",
    "    max_dist = np.amax(shortest_path_result)\n",
    "\n",
    "    input_edges = algos_graphormer.gen_edge_input(max_dist, path, attn_edge_type)\n",
    "    attn_bias = np.zeros([num_nodes + 1, num_nodes + 1], dtype=np.single)  # with graph token\n",
    "\n",
    "    # combine\n",
    "    item[\"input_nodes\"] = input_nodes + 1  # we shift all indices by one for padding\n",
    "    item[\"attn_bias\"] = attn_bias\n",
    "    item[\"attn_edge_type\"] = attn_edge_type\n",
    "    item[\"spatial_pos\"] = shortest_path_result.astype(np.int64) + 1  # we shift all indices by one for padding\n",
    "    item[\"in_degree\"] = np.sum(adj, axis=1).reshape(-1) + 1  # we shift all indices by one for padding\n",
    "    item[\"out_degree\"] = item[\"in_degree\"]  # for undirected graph\n",
    "    item[\"input_edges\"] = input_edges + 1  # we shift all indices by one for padding\n",
    "    if \"labels\" not in item:\n",
    "        item[\"labels\"] = item[\"y\"]\n",
    "\n",
    "    return item\n",
    "\n",
    "\n",
    "class GraphormerDataCollator:\n",
    "    def __init__(self, spatial_pos_max=20, on_the_fly_processing=False):\n",
    "        if not is_cython_available():\n",
    "            raise ImportError(\"Graphormer preprocessing needs Cython (pyximport)\")\n",
    "\n",
    "        self.spatial_pos_max = spatial_pos_max\n",
    "        self.on_the_fly_processing = on_the_fly_processing\n",
    "\n",
    "    def __call__(self, features: List[dict]) -> Dict[str, Any]:\n",
    "        if self.on_the_fly_processing:\n",
    "            features = [preprocess_item(i) for i in features]\n",
    "\n",
    "        if not isinstance(features[0], Mapping):\n",
    "            features = [vars(f) for f in features]\n",
    "        batch = {}\n",
    "\n",
    "        max_node_num = max(len(i[\"input_nodes\"]) for i in features)\n",
    "        node_feat_size = len(features[0][\"input_nodes\"][0])\n",
    "        edge_feat_size = len(features[0][\"attn_edge_type\"][0][0])\n",
    "        max_dist = max(len(i[\"input_edges\"][0][0]) for i in features)\n",
    "        edge_input_size = len(features[0][\"input_edges\"][0][0][0])\n",
    "        batch_size = len(features)\n",
    "\n",
    "        batch[\"attn_bias\"] = torch.zeros(batch_size, max_node_num + 1, max_node_num + 1, dtype=torch.float)\n",
    "        batch[\"attn_edge_type\"] = torch.zeros(batch_size, max_node_num, max_node_num, edge_feat_size, dtype=torch.long)\n",
    "        batch[\"spatial_pos\"] = torch.zeros(batch_size, max_node_num, max_node_num, dtype=torch.long)\n",
    "        batch[\"in_degree\"] = torch.zeros(batch_size, max_node_num, dtype=torch.long)\n",
    "        batch[\"input_nodes\"] = torch.zeros(batch_size, max_node_num, node_feat_size, dtype=torch.long)\n",
    "        batch[\"input_edges\"] = torch.zeros(\n",
    "            batch_size, max_node_num, max_node_num, max_dist, edge_input_size, dtype=torch.long\n",
    "        )\n",
    "\n",
    "        for ix, f in enumerate(features):\n",
    "            for k in [\"attn_bias\", \"attn_edge_type\", \"spatial_pos\", \"in_degree\", \"input_nodes\", \"input_edges\"]:\n",
    "                f[k] = torch.tensor(f[k])\n",
    "\n",
    "            if len(f[\"attn_bias\"][1:, 1:][f[\"spatial_pos\"] >= self.spatial_pos_max]) > 0:\n",
    "                f[\"attn_bias\"][1:, 1:][f[\"spatial_pos\"] >= self.spatial_pos_max] = float(\"-inf\")\n",
    "\n",
    "            batch[\"attn_bias\"][ix, : f[\"attn_bias\"].shape[0], : f[\"attn_bias\"].shape[1]] = f[\"attn_bias\"]\n",
    "            batch[\"attn_edge_type\"][ix, : f[\"attn_edge_type\"].shape[0], : f[\"attn_edge_type\"].shape[1], :] = f[\n",
    "                \"attn_edge_type\"\n",
    "            ]\n",
    "            batch[\"spatial_pos\"][ix, : f[\"spatial_pos\"].shape[0], : f[\"spatial_pos\"].shape[1]] = f[\"spatial_pos\"]\n",
    "            batch[\"in_degree\"][ix, : f[\"in_degree\"].shape[0]] = f[\"in_degree\"]\n",
    "            batch[\"input_nodes\"][ix, : f[\"input_nodes\"].shape[0], :] = f[\"input_nodes\"]\n",
    "            batch[\"input_edges\"][\n",
    "                ix, : f[\"input_edges\"].shape[0], : f[\"input_edges\"].shape[1], : f[\"input_edges\"].shape[2], :\n",
    "            ] = f[\"input_edges\"]\n",
    "\n",
    "        batch[\"out_degree\"] = batch[\"in_degree\"]\n",
    "\n",
    "        sample = features[0][\"labels\"]\n",
    "        if len(sample) == 1:  # one task\n",
    "            if isinstance(sample[0], float):  # regression\n",
    "                batch[\"labels\"] = torch.from_numpy(np.concatenate([i[\"labels\"] for i in features]))\n",
    "            else:  # binary classification\n",
    "                batch[\"labels\"] = torch.from_numpy(np.concatenate([i[\"labels\"] for i in features]))\n",
    "        else:  # multi task classification, left to float to keep the NaNs\n",
    "            batch[\"labels\"] = torch.from_numpy(np.stack([i[\"labels\"] for i in features], axis=0))\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186d88e-71b5-4a1e-965f-0e5e7cda686e",
   "metadata": {},
   "source": [
    "# Data prerpoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc974c-3918-4c87-9643-8dda1b0b55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getshortest_path(datapoint):\n",
    "    num_nodes=len(datapoint['node_feat'])\n",
    "    edge_index = datapoint['edge_index']\n",
    "    adj = np.zeros([num_nodes, num_nodes], dtype=bool)\n",
    "    adj[edge_index[0], edge_index[1]] = True\n",
    "    shortest_path_result, path = algos_graphormer.floyd_warshall(adj)\n",
    "    max_dist = np.amax(shortest_path_result)\n",
    "    return {\"max_dist\":max_dist, \"path\": path}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f8c98-1858-4570-a139-4177015321e9",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def processItemForGraphormer(graph, yi):\n",
    "    processed = preprocess_item(\n",
    "                 {\"node_feat\":graph.x.tolist(),\n",
    "                 \"edge_index\":graph.edge_index.tolist(),\n",
    "                 \"edge_attr\":graph.edge_attr.tolist(),\n",
    "                 \"num_nodes\":len(graph.x),\n",
    "                 'y': yi\n",
    "                })\n",
    "    processed['attn_edge_type_ORIG'] = np.array(processed['attn_edge_type'])+0\n",
    "    processed['input_nodes_ORIG'] = np.array(processed['input_nodes'])+0\n",
    "    return processed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0bdc0-89c4-494d-a76a-5cc7071cca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Dataset\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, dataset: pd.DataFrame, node_mask_percent=0.15, edge_mask_percent=0.2):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.node_mask_percent = node_mask_percent\n",
    "        self.edge_mask_percent = edge_mask_percent\n",
    "        \n",
    "        self.input_ids = []\n",
    "        self.mask = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.yi = torch.tensor(np.full(( 768), 1).tolist()) \n",
    "        \n",
    "        self.dataset['graph'] = self.dataset['Smiles'].progress_apply(self.get_graph_from_smiles)\n",
    "        \n",
    "    \n",
    "        self.dataset['graphormerdata'] = self.dataset['graph'].progress_apply(\n",
    "              lambda graph:   processItemForGraphormer(graph, self.yi)                    \n",
    "        )                                                     \n",
    "                                                                     \n",
    "        self.dataset['graphormerdataRAW'] = self.dataset['graph'].progress_apply(\n",
    "              lambda graph:\n",
    "#       preprocess_item(\n",
    "                 {\"node_feat\":graph.x.tolist(),\n",
    "                 \"edge_index\":graph.edge_index.tolist(),\n",
    "                 \"edge_attr\":graph.edge_attr.tolist(),\n",
    "                 \"num_nodes\":len(graph.x),\n",
    "                 'y': self.yi\n",
    "                }\n",
    "#         )                      \n",
    "        ) \n",
    "        \n",
    "        self.dataset['shortest_path'] = self.dataset['graphormerdataRAW'].progress_apply(\n",
    "                   lambda datapoint:\n",
    "                        getshortest_path(datapoint)\n",
    "                    )\n",
    "        \n",
    "        self.maskedGraphAtom = torch.tensor([[len(ATOM_LIST),0]],dtype=torch.long)\n",
    "        self.edgeGraphMask = torch.tensor([len(BOND_LIST) + 1, len(BONDDIR_LIST)], dtype=torch.long)\n",
    "\n",
    "        for descriptors_of_substructures in self.dataset['descriptors']:\n",
    "            shifter.shift(descriptors_of_substructures)\n",
    "\n",
    "        self.maximum = 0\n",
    "\n",
    "        for mol in self.dataset['descriptors']:\n",
    "            for substr in mol:\n",
    "                if substr == '$':\n",
    "                    continue\n",
    "                for descriptor in substr:\n",
    "                    for i in descriptor:\n",
    "                        self.maximum = max(self.maximum, i)\n",
    "        \n",
    "        self.tokenize_descriptors(self.dataset)\n",
    "        l =[]\n",
    "        inp = []\n",
    "        msk = []\n",
    "        for i in range(len(self.labels)):\n",
    "            l.append(self.labels[i])\n",
    "            inp.append(self.input_ids[i])\n",
    "            msk.append(self.mask[i])\n",
    "\n",
    "        self.dataset['labels'] = l\n",
    "        self.dataset['input_ids'] = inp\n",
    "        self.dataset['attention_mask'] = msk\n",
    "        \n",
    "        self.dataset['mlm'] = self.dataset.progress_apply(self.apply_mlm, axis=1)\n",
    "        self.dataset['tokens'] = self.dataset['mlm']\n",
    "        \n",
    " \n",
    "    def get_graph_from_smiles(self, smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return torch.tensor([[], []], dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    torch.tensor(np.array([]), dtype=torch.long), \\\n",
    "                    0\n",
    "    \n",
    "        N = mol.GetNumAtoms()\n",
    "        M = mol.GetNumBonds()\n",
    "    \n",
    "        type_idx = []\n",
    "        chirality_idx = []\n",
    "        atomic_number = []\n",
    "        \n",
    "        for atom in mol.GetAtoms():\n",
    "            type_idx.append(ATOM_LIST.index(atom.GetAtomicNum()))\n",
    "            chirality_idx.append(CHIRALITY_LIST.index(atom.GetChiralTag()))\n",
    "            atomic_number.append(atom.GetAtomicNum())\n",
    "        \n",
    "        x1 = torch.tensor(type_idx, dtype=torch.long).view(-1,1)\n",
    "        x2 = torch.tensor(chirality_idx, dtype=torch.long).view(-1,1)\n",
    "        node_feat = torch.cat([x1, x2], dim=-1)\n",
    "    \n",
    "        row, col, edge_feat = [], [], []\n",
    "        for bond in mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            row += [start, end]\n",
    "            col += [end, start]\n",
    "            \n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "            edge_feat.append([\n",
    "                BOND_LIST.index(bond.GetBondType()),\n",
    "                BONDDIR_LIST.index(bond.GetBondDir())\n",
    "            ])\n",
    "    \n",
    "        edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(edge_feat, dtype=torch.long)\n",
    "        num_nodes = N\n",
    "        num_edges = M\n",
    "        return Data(x=node_feat, edge_index=edge_index, edge_attr=edge_attr)\n",
    "         \n",
    "\n",
    "    def get_augmented_graph_copy(self, node_feat, edge_index, edge_attr, N, M):\n",
    "        num_mask_nodes = max([1, math.floor(self.node_mask_percent * N)])\n",
    "        #num_mask_nodes = 1\n",
    "        num_mask_edges = max([0, math.floor(self.edge_mask_percent * M)])\n",
    "\n",
    "        \n",
    "        mask_nodes = random.sample(list(range(N)), num_mask_nodes)\n",
    "        mask_edges_single = random.sample(list(range(M)), num_mask_edges)\n",
    "        \n",
    "        \n",
    "        mask_edges = [2*i for i in mask_edges_single] + [2*i+1 for i in mask_edges_single]\n",
    "\n",
    "        \n",
    "        node_feat_new = deepcopy(node_feat)\n",
    "        \n",
    "        node_feat_new[mask_nodes] = (node_feat_new[mask_nodes][:,:]*0 + self.maskedGraphAtom)\n",
    "            \n",
    "        edge_attr_new = edge_attr\n",
    "        edge_attr_new[mask_edges] =  self.edgeGraphMask\n",
    "\n",
    "        return Data(x=node_feat_new, edge_index=edge_index, edge_attr=edge_attr_new)\n",
    "\n",
    "    \n",
    "    def tokenize_descriptors(self, data):\n",
    "        sample = tokenizer.tokenize(data['descriptors'], max_length=512)\n",
    "        \n",
    "        self.labels.append(torch.tensor(sample['input_ids']))\n",
    "        self.mask.append(torch.tensor(sample['attention_mask']))\n",
    "        self.input_ids.append(self.mlm(self.labels[-1].detach().clone()))\n",
    "        \n",
    "        self.input_ids = torch.cat(self.input_ids)\n",
    "        self.mask = torch.cat(self.mask)\n",
    "        \n",
    "        self.labels = torch.cat(self.labels)\n",
    "\n",
    "    def mlm(self, tensor):\n",
    "        rand = torch.rand(tensor.shape)\n",
    "        mask_arr = (rand < .15) * (tensor != 0) * (tensor != 1) * (tensor != 2)\n",
    "        for i in range(tensor.shape[0]):\n",
    "            selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "            tensor[i, selection] = 4\n",
    "        return tensor\n",
    "        \n",
    "    def tokenize(self, item):\n",
    "        sample = self.tokenizer(item, truncation=True, max_length=512, padding='max_length')\n",
    "        return (torch.tensor(sample.input_ids), \n",
    "                torch.tensor(sample.attention_mask), \n",
    "                torch.tensor(sample.input_ids)\n",
    "               )\n",
    "\n",
    "    def apply_mlm(self, sample):\n",
    "        labels = torch.tensor(sample.input_ids)\n",
    "        attention_mask = torch.tensor(sample.attention_mask)\n",
    "        input_ids = torch.tensor(sample.input_ids)\n",
    "        return Data(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        bert = self.dataset['mlm'][index]\n",
    "        graph = self.dataset['graph'][index]\n",
    "        \n",
    "        return graph, bert\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def get(self):\n",
    "        pass\n",
    "    def len(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dfd5e8-5cb6-4aa0-878b-6444d9e89652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoleculeDataset(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68838c6f-cfd1-407f-91cc-2f2ddfa83e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset['mlm'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45effc79-94ba-40da-a5c6-7478a0a29057",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_train = len(dataset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(np.floor(config['dataset']['valid_size'] * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bf7fb-6ba9-4c4c-9e09-7e1b6f57cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def pad_to_shape(tensor, target_shape):\n",
    "    current_shape = tensor.shape\n",
    "    num_dims = len(current_shape)\n",
    "    \n",
    "    if num_dims != len(target_shape):\n",
    "        raise ValueError(f\"Tensor has {num_dims} dimensions but target shape has {len(target_shape)} dimensions.\")\n",
    "    \n",
    "    # Calculate padding needed for each dimension\n",
    "    padding = []\n",
    "    for i in range(num_dims - 1, -1, -1):  # Iterate from the last dimension backwards\n",
    "        if target_shape[i] < current_shape[i]:\n",
    "            raise ValueError(f\"Target shape at dimension {i} is smaller than the tensor shape.\")\n",
    "        padding.append(0)  # No padding on the left\n",
    "        padding.append(target_shape[i] - current_shape[i])  # Right side padding\n",
    "        \n",
    "\n",
    "    # Apply padding\n",
    "    padded_tensor = F.pad(tensor, padding)\n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48f968-3fe8-40a7-88f8-1619524f9198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class CustomBatchDataset(IterableDataset):\n",
    "    \n",
    "    def setTrain(self,train = True):\n",
    "        if train:\n",
    "            self.sample_id = self.train_idx\n",
    "            self.train = True\n",
    "        else:\n",
    "            self.sample_id = self.valid_idx\n",
    "            self.train = False\n",
    "    \n",
    "    def __init__(self, dataframe,dataset, train_idx,valid_idx, batch_size):\n",
    "        \n",
    "        self.y = torch.tensor(np.full((config['batch_size'] * 2, 768), 1).tolist())\n",
    "        self.yi = torch.tensor(np.full(( 768), 1).tolist())\n",
    "        self.dataset=dataset\n",
    "        self.dataframe = dataframe\n",
    "        self.sample_id = train_idx\n",
    "        self.valid_idx = valid_idx\n",
    "        self.train_idx = train_idx\n",
    "        self.batch_size = batch_size\n",
    "        self.train = True\n",
    "        \n",
    "        input_ids = [e['input_ids'] for e in dataframe['tokens']]\n",
    "        self.input_ids = torch.stack(input_ids)\n",
    "\n",
    "        attention_mask = [e['attention_mask'] for e in dataframe['tokens']]\n",
    "        self.attention_mask = torch.stack(attention_mask)\n",
    "\n",
    "        labels = [e['labels'] for e in dataframe['tokens']]\n",
    "        self.labels = torch.stack(labels)\n",
    "\n",
    "        self.graphs = [e for e in dataframe['graph']]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Custom iterator that yields batches of data and labels.\n",
    "        \"\"\"\n",
    "        # Get the total number of samples\n",
    "        total_samples = (len(self.sample_id)//self.batch_size)*self.batch_size\n",
    "        if self.train:\n",
    "            np.random.shuffle(self.sample_id)\n",
    "        # Yield minibatches\n",
    "        for i in range(0, total_samples, self.batch_size):\n",
    "             \n",
    "            S = self.sample_id[ i : i + self.batch_size]\n",
    "            \n",
    "            inp_Idx =  self.input_ids[S]\n",
    "            rand = torch.rand(inp_Idx.shape)\n",
    "            mask_arr = (rand < .15) * (inp_Idx != 0) * (inp_Idx != 1) * (inp_Idx != 2)\n",
    "            inp_Idx[mask_arr] = 4\n",
    "            atte = self.attention_mask[S]\n",
    "            labe = self.labels[S]\n",
    "            \n",
    "            SS = S+S\n",
    "            graphdataProcessed =  [ self.dataframe.graphormerdata[i] for i in SS]\n",
    "\n",
    "            shortestPath =  [ self.dataframe.shortest_path[i] for i in SS]\n",
    "            selId = [ \n",
    "                    random.sample(\n",
    "                     list(range(len(g[\"node_feat\"]))),  \n",
    "                                      max([1, math.floor(self.dataset.node_mask_percent \n",
    "                                                         * len(g[\"node_feat\"]))])\n",
    "                             )\n",
    "                                            for g  in  graphdataProcessed ]\n",
    "             \n",
    "            for g, selidi in zip(graphdataProcessed,selId):\n",
    "                g[\"input_nodes\"]= g[\"input_nodes_ORIG\"] +0\n",
    "                for s in selidi:\n",
    "                    g[\"input_nodes\"][s,0]=self.dataset.maskedGraphAtom[0][0]\n",
    "\n",
    "            \n",
    "            eselId = [ \n",
    "                 random.sample(\n",
    "                                 list(range(len(g['edge_index'][0])//2)),  \n",
    "                                  max([0, math.floor(self.dataset.edge_mask_percent * (len(g['edge_index'][0])//2))])\n",
    "                         )\n",
    "                                        for g   in   graphdataProcessed ]\n",
    "            for g, eid  in zip(graphdataProcessed, eselId):\n",
    "                g['attn_edge_type'] = np.array(g['attn_edge_type_ORIG'])+0\n",
    "                for e in eid:\n",
    "                    fn = g['edge_index'][0][2*e]\n",
    "                    tn = g['edge_index'][1][2*e]\n",
    "                    g['attn_edge_type'][fn,tn,:] = self.dataset.edgeGraphMask\n",
    "                    fn = g['edge_index'][0][2*e+1]\n",
    "                    tn = g['edge_index'][1][2*e+1]\n",
    "                    g['attn_edge_type'][fn,tn,:] = self.dataset.edgeGraphMask\n",
    "            \n",
    "            \n",
    "            for g, sp  in zip(graphdataProcessed, shortestPath):\n",
    "                edge_attr = g['attn_edge_type']\n",
    "                \n",
    "                input_edges = algos_graphormer.gen_edge_input(sp['max_dist'], sp['path'], edge_attr)\n",
    "\n",
    "                g['input_edges'] = input_edges+1\n",
    "            \n",
    "            yield inp_Idx, atte, labe, graphdataProcessed#, g1, g2 \n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_idx)//self.batch_size\n",
    "        else:\n",
    "            return len(self.valid_idx)//self.batch_size\n",
    "\n",
    "\n",
    "custom_batch_dataset = CustomBatchDataset(dataframe, dataset, train_idx,valid_idx, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a56144-3102-4a21-b86b-8e851dc97026",
   "metadata": {},
   "source": [
    "### Create Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430d192-999e-4e08-aa35-c8b764917137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.graphormer.collating_graphormer import GraphormerDataCollator\n",
    "from transformers.models.graphormer.collating_graphormer import preprocess_item, GraphormerDataCollator\n",
    "\n",
    "model_name_base = 'graphormer-base-pcqm4mv1'\n",
    "model_name = 'clefourrier/graphormer-base-pcqm4mv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390bc35-7de5-453e-a995-2d86f0bbf3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, device, batch_size, temperature, use_cosine_similarity):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.mask_samples_from_same_repr = self._get_correlated_mask().type(torch.bool)\n",
    "        self.similarity_function = self._get_similarity_function(use_cosine_similarity)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_similarity_function(self, use_cosine_similarity):\n",
    "        if use_cosine_similarity:\n",
    "            self._cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
    "            return self._cosine_simililarity\n",
    "        else:\n",
    "            return self._dot_simililarity\n",
    "\n",
    "    def _get_correlated_mask(self):\n",
    "        diag = np.eye(2 * self.batch_size)\n",
    "        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n",
    "        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n",
    "        mask = torch.from_numpy((diag + l1 + l2))\n",
    "        mask = (1 - mask).type(torch.bool)\n",
    "        return mask.to(self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dot_simililarity(x, y):\n",
    "        v = torch.tensordot(x.unsqueeze(1), y.T.unsqueeze(0), dims=2)\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, C, 2N)\n",
    "        # v shape: (N, 2N)\n",
    "        return v\n",
    "\n",
    "    def _cosine_simililarity(self, x, y):\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, 2N, C)\n",
    "        # v shape: (N, 2N)\n",
    "        v = self._cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n",
    "        return v\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        representations = torch.cat([zjs, zis], dim=0)\n",
    "\n",
    "        similarity_matrix = self.similarity_function(representations, representations)\n",
    "\n",
    "        # filter out the scores from the positive samples\n",
    "        l_pos = torch.diag(similarity_matrix, self.batch_size)\n",
    "        r_pos = torch.diag(similarity_matrix, -self.batch_size)\n",
    "        positives = torch.cat([l_pos, r_pos]).view(2 * self.batch_size, 1)\n",
    "        negatives = similarity_matrix[self.mask_samples_from_same_repr].view(2 * self.batch_size, -1)\n",
    "\n",
    "        logits = torch.cat((positives, negatives), dim=1)\n",
    "        logits = logits.abs() + 0.0001\n",
    "        logits = torch.log(logits)\n",
    "        logits /= self.temperature\n",
    "        \n",
    "        labels = torch.zeros(2 * self.batch_size).to(self.device).long()\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        return loss / (2 * self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93944aa4-9c68-4e6e-9d99-229bd5b70db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GraphormerForGraphClassification\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "\n",
    "class GraphormerDataCollator_():\n",
    "    def __init__(self):\n",
    "        self.data_collator = GraphormerDataCollator()\n",
    "\n",
    "    def __call__(self, features):\n",
    "        for mol in features:\n",
    "            if mol['num_nodes'] == 1:\n",
    "                features.remove(mol)\n",
    "        return self.data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef89d4-b7ac-4a86-ab14-67383fd0f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"efcp_transformer\",\n",
    "    name=\"RobertaForMaskedLM + Graphormer-speed-up-2.5m\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66254640-38dc-4da6-bccf-634174aca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import RobertaConfig\n",
    "from torch import nn\n",
    "\n",
    "class MolecularBertGraph(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MolecularBertGraph, self).__init__()\n",
    "        self.batch_size = config['batch_size']\n",
    "\n",
    "        roberta_config = RobertaConfig(\n",
    "            vocab_size=30_522,\n",
    "            max_position_embeddings=514,\n",
    "            hidden_size=768,\n",
    "            num_attention_heads=12,\n",
    "            num_hidden_layers=6,\n",
    "            type_vocab_size=1\n",
    "        )\n",
    "        self.bert = RobertaForMaskedLM(roberta_config)\n",
    "        \n",
    "        self.data_collator = GraphormerDataCollator_()\n",
    "        \n",
    "        self.graph_model = GraphormerForGraphClassification.from_pretrained(\n",
    "            model_name, \n",
    "            num_classes=1,\n",
    "            ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    "            ).to(device)     # GraphModel(**config['model'])\n",
    "        self.graph_model.classifier = nn.Identity()\n",
    "#         print(self.graph_model)\n",
    "        # self.graph_model = self._load_pre_trained_weights(self.graph_model)\n",
    "\n",
    "        self.out_graph_linear = torch.nn.Linear(768 * 2, 768, bias=True)\n",
    "\n",
    "        self.out_graph_projection1 = torch.nn.Linear(768, 768, bias=True)\n",
    "\n",
    "        self.bn1_graph = nn.BatchNorm1d(768)\n",
    "\n",
    "        self.out_graph_projection2 = torch.nn.Linear(768, 768, bias=True)\n",
    "\n",
    "        self.bn2_graph = nn.BatchNorm1d(768)\n",
    "\n",
    "        self.out_bert_projection1 = torch.nn.Linear(768, 768, bias=True)\n",
    "\n",
    "        self.bn1_bert = nn.BatchNorm1d(768)\n",
    "\n",
    "        self.out_bert_projection2 = torch.nn.Linear(768, 768, bias=True)\n",
    "        \n",
    "        self.bn2_bert = nn.BatchNorm1d(768)\n",
    "\n",
    "        # contrastive loss for MolCLR\n",
    "        self.nt_xent_criterion = NTXentLoss(device, self.batch_size, **config['loss'])\n",
    "        # cosine distance as loss between models\n",
    "        self.cosine_sim = torch.nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, inp_Idx, atte, labe, graphdataProcessed):\n",
    "        bert_output = self.bert(input_ids=inp_Idx, \n",
    "                                 attention_mask=atte,\n",
    "                                 labels=labe, output_hidden_states=True)\n",
    "        bert_loss = bert_output.loss\n",
    "        bert_emb = bert_output.hidden_states[0][:, 0, :] # take emb for CLS token\n",
    "\n",
    "        graph_loss, hidden_states_1, hidden_states_2 = self.graph_step(graphdataProcessed)\n",
    "    \n",
    "        graph_emb = self.out_graph_linear(torch.cat((hidden_states_1, hidden_states_2), dim=-1)).mean(axis=0)\n",
    "        graph_emb_projected1 = self.out_graph_projection1(graph_emb)\n",
    "        graph_emb_projected_bn1 = self.bn1_graph(graph_emb_projected1)\n",
    "        graph_emb_projected2 = self.out_graph_projection2(torch.nn.functional.relu(graph_emb_projected_bn1))\n",
    "        graph_emb_projected_bn2 = self.bn2_graph(graph_emb_projected2)\n",
    "\n",
    "        bert_emb_projected1 = self.out_bert_projection1(bert_emb)\n",
    "        bert_emb_projected_bn1 = self.bn1_bert(bert_emb_projected1)\n",
    "        bert_emb_projected2 = self.out_bert_projection2(torch.nn.functional.relu(bert_emb_projected_bn1))\n",
    "        bert_emb_projected_bn2 = self.bn2_bert(bert_emb_projected2)\n",
    "\n",
    "        bimodal_loss = self.nt_xent_criterion(bert_emb_projected_bn2, graph_emb_projected_bn2)\n",
    "\n",
    "        return bert_loss, graph_loss, bimodal_loss, graph_emb_projected_bn2, bert_emb_projected_bn2\n",
    "\n",
    "    def graph_step(self, graphdataProcessed):\n",
    "        batch = {}\n",
    "        for k in ['attn_bias', 'attn_edge_type', 'spatial_pos', 'in_degree', 'input_nodes', 'input_edges', 'out_degree', 'labels']:\n",
    "            shp = np.max([  np.array(e[k]).shape for e in graphdataProcessed], 0)\n",
    "            batch[k] = torch.stack([pad_to_shape(torch.tensor(e[k]), shp) for e in graphdataProcessed])\n",
    "        \n",
    "        input_batch = { k: v.to(device) for k, v in batch.items() }\n",
    "        outputs = self.graph_model(**input_batch)\n",
    "        # get the representations and the projections\n",
    "        zis = outputs.logits[:config['batch_size']]\n",
    "        zjs = outputs.logits[config['batch_size']:]\n",
    "\n",
    "        ris = outputs.hidden_states[0][:, 0:config['batch_size'], :].to(device)\n",
    "        rjs = outputs.hidden_states[0][:, config['batch_size']:config['batch_size']*2, :].to(device)\n",
    "        \n",
    "        zis = torch.nn.functional.normalize(zis, dim=1)\n",
    "        zjs = torch.nn.functional.normalize(zjs, dim=1)\n",
    "    \n",
    "         \n",
    "        loss = self.nt_xent_criterion(zis, zjs)\n",
    "        return loss, ris, rjs\n",
    "\n",
    "model = MolecularBertGraph().to(device);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b0c73-a897-407e-a8c7-158283f97de4",
   "metadata": {},
   "source": [
    "### Define utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04001413-80f4-4663-ab5d-a107e839c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = config['epochs']\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), config['init_lr'], \n",
    "    weight_decay=eval(config['weight_decay'])\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=config['epochs']-config['warm_up'], \n",
    "    eta_min=0, last_epoch=-1\n",
    ")\n",
    "num_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a951a1-7c75-47bd-b275-9693eb22fe95",
   "metadata": {},
   "source": [
    "### Training (with validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f660cb2-97a3-4102-b85e-c6e23c84429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = config['loss_params']['alpha']\n",
    "beta = config['loss_params']['beta']\n",
    "gamma = config['loss_params']['gamma']\n",
    "alpha, beta, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea2e1e-8d54-4f03-914f-6b6328b5da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6377bd-fe1d-4246-8fc6-00b34bfbc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(custom_batch_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96388fce-0dc6-43a3-b800-5133ea476cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    custom_batch_dataset.setTrain(True)\n",
    "    train_tqdm = tqdm(custom_batch_dataset, unit=\"batch\")\n",
    "    train_tqdm.set_description(f'Epoch {epoch_counter}')\n",
    "    bert_loss_sum, graph_model_loss_sum, bimodal_loss_sum, loss_sum = 0, 0, 0, 0\n",
    "    model.train()\n",
    "         \n",
    "    for inp_Idx, atte, labe, graphdataProcessed in train_tqdm:\n",
    "     \n",
    "        if True:\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            bert_loss, graph_loss, bimodal_loss, emb1, emb2 = model(inp_Idx.to(device), atte.to(device), labe.to(device), graphdataProcessed)\n",
    "    \n",
    "            loss = alpha * bert_loss + beta * graph_loss + gamma * bimodal_loss\n",
    "            loss.backward()\n",
    "    \n",
    "            bert_loss_sum += bert_loss.item()\n",
    "            graph_model_loss_sum += graph_loss.item()\n",
    "            bimodal_loss_sum += bimodal_loss.item()\n",
    "            loss_sum += loss.item()\n",
    "    \n",
    "            wandb.log({\"bert_loss/train\": bert_loss })\n",
    "            wandb.log({\"graph_loss/train\": graph_loss})\n",
    "            wandb.log({\"bimodal_loss/train\": bimodal_loss})\n",
    "            wandb.log({\"loss/train\": loss})\n",
    "    \n",
    "            optimizer.step()\n",
    "             \n",
    "    return bert_loss_sum / len(custom_batch_dataset), graph_model_loss_sum / len(custom_batch_dataset), bimodal_loss_sum / len(custom_batch_dataset), loss_sum / len(custom_batch_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af92a73-77ad-4bd7-9727-7bb5337fd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop():\n",
    "    bert_loss_sum, graph_model_loss_sum, bimodal_loss_sum, loss_sum = 0, 0, 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    custom_batch_dataset.setTrain(False)\n",
    "         \n",
    "    for batch_idx, (inp_Idx, atte, labe, graphdataProcessed  ) in enumerate(custom_batch_dataset):\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                bert_loss, graph_loss, bimodal_loss, emb1, emb2 = model(inp_Idx.to(device), atte.to(device), labe.to(device), graphdataProcessed)\n",
    "\n",
    "    \n",
    "            loss = alpha * bert_loss + beta * graph_loss + gamma * bimodal_loss\n",
    "    \n",
    "            bert_loss_sum += bert_loss.item()\n",
    "            graph_model_loss_sum += graph_loss.item()\n",
    "            bimodal_loss_sum += bimodal_loss.item()\n",
    "            loss_sum += loss.item()\n",
    "        \n",
    "        except:\n",
    "            continue\n",
    "    return bert_loss_sum / len(custom_batch_dataset), graph_model_loss_sum / len(custom_batch_dataset), bimodal_loss_sum / len(custom_batch_dataset), loss_sum / len(custom_batch_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec2b30-1b08-48ca-8e72-4b8e2c8b6f96",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd36a8-610d-4760-a984-79bf17e5b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model_checkpoints_folder = os.path.join('ckpts')\n",
    "dir_name = datetime.now().strftime('%b%d_%H-%M-%S_graphormer_fast')\n",
    "log_dir = os.path.join(model_checkpoints_folder, dir_name)\n",
    "_save_config_file(config, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a426df-461e-4180-9186-c5471b4df374",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 0\n",
    "valid_n_iter = 0\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch_counter in range(num_epoch):\n",
    "    bert_loss, graph_loss, bimodal_loss, loss = train_loop()\n",
    "\n",
    "    wandb.log({\"bert_loss/train\": bert_loss}, step=epoch_counter)\n",
    "    wandb.log({\"graph_loss/train\": graph_loss}, step=epoch_counter)\n",
    "    wandb.log({\"bimodal_loss/train\": bimodal_loss}, step=epoch_counter)\n",
    "    wandb.log({\"loss/train\": loss}, step=epoch_counter)\n",
    "\n",
    "    bert_loss, graph_loss, bimodal_loss, loss = eval_loop()\n",
    "\n",
    "    wandb.log({\"bert_loss/eval\": bert_loss}, step=epoch_counter)\n",
    "    wandb.log({\"graph_loss/eval\": graph_loss}, step=epoch_counter)\n",
    "    wandb.log({\"bimodal_loss/eval\": bimodal_loss}, step=epoch_counter)\n",
    "    wandb.log({\"loss/eval\": loss}, step=epoch_counter)\n",
    "    \n",
    "    if loss < best_valid_loss:\n",
    "        best_valid_loss = loss\n",
    "        torch.save(model.state_dict(), os.path.join(log_dir, 'model.pth'))\n",
    "    \n",
    "    if (epoch_counter + 1) % config['save_every_n_epochs'] == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(log_dir, 'model_{}.pth'.format(str(epoch_counter))))\n",
    "\n",
    "    # warmup for the first few epochs\n",
    "    if epoch_counter >= config['warm_up']:\n",
    "        #wandb.log({\"cosine_lr_decay\": scheduler.get_last_lr()[0]}, step=epoch_counter)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad7b9-f82b-4936-bd4f-26266cbb6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9ed63-eaf7-4e39-b91b-cb8d9aa00ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_batch_dataset.setTrain(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "001bd6968bdf44c29ce98b0f2f43cfca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_697fd7a81c534176934ecbb1bab6aea4",
       "max": 128,
       "style": "IPY_MODEL_0d11365ec2c84fef8dae7febae85cd61",
       "value": 128
      }
     },
     "01bcf7bb0bd64d5ba65aa7e77c2d7766": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_28f517833bfc448a8eda2de07410524b",
       "style": "IPY_MODEL_ec1a43e481a0461895189cad09ed1643"
      }
     },
     "034248d93c724da98b492f23696f004d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_49f0cd3b748d402b9cd56bfbb5e5ef45",
       "style": "IPY_MODEL_f69eacdc16b34ec79e8194cfcce639ec",
       "value": "Map: 100%"
      }
     },
     "06fb79eaedd542f5999cfa567dc1c0c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "07c43f7c3dda454db945282137b6955e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3f62283153414e66a5d08b95525f4fc8",
       "style": "IPY_MODEL_33a7596352db4470a7baf43cf7f4af95",
       "value": " 128/128 [00:01&lt;00:00, 84.04 examples/s]"
      }
     },
     "08e3c2b3bbee41a3af0c93d2e814100a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_aec4f986c470429ea7ac919821ef307e",
       "max": 128,
       "style": "IPY_MODEL_d1e5e029624b45f39b4a3a7e1d8c97c1",
       "value": 128
      }
     },
     "0d11365ec2c84fef8dae7febae85cd61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "10454f3f548044a38b93cd87f33de5b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "120ff4ba880241a3bf54b45bbbc608c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "12c8f9cf3a3b4a0b9d64ceba8a6e59d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "12db03965c26447fa8eda1a68bba2479": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "12de4ab0f5c44c829b489a757c15d6d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7ae98f58290c411dbb869e72c872d462",
        "IPY_MODEL_001bd6968bdf44c29ce98b0f2f43cfca",
        "IPY_MODEL_1c937906af9b474489766dbd132681ba"
       ],
       "layout": "IPY_MODEL_ef7255e151cc49e5a569a801f925ef98"
      }
     },
     "14627d7ddb2441e38cefe1364e15312d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2a1152efc937483c834550b9e0c93a06",
       "max": 128,
       "style": "IPY_MODEL_29f1707225504c9291a5033550bc5c7f",
       "value": 128
      }
     },
     "160ef709d89d4432a9e636cb96c31b93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "17f93152a35e4882a5fbc2d661ac0e2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_49fa17bed0ce42ef97d8ec78193f14fd",
       "style": "IPY_MODEL_f3900afec7f3412e9a32a5e1a0159cf2",
       "value": " 128/128 [00:01&lt;00:00, 100.34 examples/s]"
      }
     },
     "19a732e7382c4341bb3d0146035ad15b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1c937906af9b474489766dbd132681ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_63b7a47542d34c1899b515eddcaaf23c",
       "style": "IPY_MODEL_c09f3cf15b76434da0a2df8e8bc59b58",
       "value": " 128/128 [00:01&lt;00:00, 122.10 examples/s]"
      }
     },
     "1f39d98491ad455a8b4c8ac78b846f09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_50fbfc90c1fc49c4a2610a6c6b2f5882",
        "IPY_MODEL_14627d7ddb2441e38cefe1364e15312d",
        "IPY_MODEL_55a7116f3c9f41b2b2370f5af42b25c3"
       ],
       "layout": "IPY_MODEL_a357cd829c9e4459b3a388bab37cfea5"
      }
     },
     "1fc145cee352441fab2a53dca110a099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cc8806af10c34698b0e151752dbea9be",
       "style": "IPY_MODEL_f8dc05ae8d8547e68e9b386d1867ce80",
       "value": " 128/128 [00:01&lt;00:00, 101.60 examples/s]"
      }
     },
     "21b649a772e14288b6e4b6036d717649": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "23423d1863f14371aeb763cd5b918120": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "234dfebf7ba3461783121b4c1d93f46b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_555399d0e67e40cca8b69341290a434d",
        "IPY_MODEL_c8c1e8910b5945758e4b4690b006c7c5",
        "IPY_MODEL_8c08c27b60c8441caa1f142b9b0f5249"
       ],
       "layout": "IPY_MODEL_3909ca631e72473ea9d96a4c997d32cc"
      }
     },
     "23bae0161d64463b9d012541c3c9b20a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "24bf1e465f394cd49c67b90a59f5f8ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_89778ed8510748b89c649ed5fdd2cb52",
       "style": "IPY_MODEL_e68b085c599f4115b01e71b0266d5ac2",
       "value": " 128/128 [00:01&lt;00:00, 126.64 examples/s]"
      }
     },
     "28f517833bfc448a8eda2de07410524b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "298a7ea0a1e54e3ea7e54dfccba227a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "29f1707225504c9291a5033550bc5c7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2a1152efc937483c834550b9e0c93a06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2d8718ff539b422ba150d19b1c68cf85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2e14035df25f45c5a652a8f26bc16d5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_468a04876ddf4a7fad9956b6fe02610d",
       "max": 1,
       "style": "IPY_MODEL_d8feacb594104eceab7f006dd7b5f455"
      }
     },
     "2fc542818b684c57b999ce4bba15902d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "339178664a554eacb8679a4fb73583aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_c53a27d0baed42d9be4193d737abcb23",
       "max": 128,
       "style": "IPY_MODEL_714103c52ec946ed90402f2b4b8bea0a",
       "value": 128
      }
     },
     "33a7596352db4470a7baf43cf7f4af95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "366fc6f1c3614cec8941cb49d9aed872": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fd7c6787e1274899ba35fc4e9de188c7",
       "style": "IPY_MODEL_b60964fa17cd4a138e095ab8f16bc451",
       "value": " 11/1406 [07:05&lt;10:50:08, 27.96s/batch, bert_loss=9.28, bimodal_loss=28.7, graph_loss=3.22, loss=100]"
      }
     },
     "3909ca631e72473ea9d96a4c997d32cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "394efdce51744e13b6d2828b280f5c3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39abe8a26f99473f9f318dee28f0bdd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3e255d7459854b3dafca5b52e9178f66",
        "IPY_MODEL_08e3c2b3bbee41a3af0c93d2e814100a",
        "IPY_MODEL_17f93152a35e4882a5fbc2d661ac0e2a"
       ],
       "layout": "IPY_MODEL_dfca09d1256e4b0896deefa87d946cb6"
      }
     },
     "39b82e0a0882436a9e4302aec036d8a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3b15266bb8284ab08ae35c0465f27d78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3e1a154666314b9399721d8952adfcd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_be92955980a54daf881005f297b38db8",
       "style": "IPY_MODEL_9f4bbd7d49094f1786792a29e82a3a1a",
       "value": "Map: 100%"
      }
     },
     "3e255d7459854b3dafca5b52e9178f66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_69aa7eb736d94844ac2cb274ca6710cf",
       "style": "IPY_MODEL_e3d89def077d47ec9c87d23747da693c",
       "value": "Map: 100%"
      }
     },
     "3f62283153414e66a5d08b95525f4fc8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40cb9b36f03e40c08caa687de04d2ab4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "41cc1ba4704e409688674182b17e9b22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4200baa8f98544df9099f6299ba94760": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "468a04876ddf4a7fad9956b6fe02610d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "46907be027a94ad18b4bd1bf18852b9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_01bcf7bb0bd64d5ba65aa7e77c2d7766",
        "IPY_MODEL_2e14035df25f45c5a652a8f26bc16d5d"
       ],
       "layout": "IPY_MODEL_f5559769f8144db1930c873fb955c0b1"
      }
     },
     "4759aff346d94af9a829675ef0faa6e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_7617098b901a4c8b82acac76734f88cd",
       "max": 128,
       "style": "IPY_MODEL_12c8f9cf3a3b4a0b9d64ceba8a6e59d8",
       "value": 128
      }
     },
     "49f0cd3b748d402b9cd56bfbb5e5ef45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "49fa17bed0ce42ef97d8ec78193f14fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4a3e9fb9819a457183a191759b1e96ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8c540762e8ca4828a5db5346ffb16ba7",
        "IPY_MODEL_4759aff346d94af9a829675ef0faa6e7",
        "IPY_MODEL_a762ff4e5f984156ae84c74b0c69259f"
       ],
       "layout": "IPY_MODEL_2d8718ff539b422ba150d19b1c68cf85"
      }
     },
     "50fbfc90c1fc49c4a2610a6c6b2f5882": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_917859aec4a64f55ab05ede560c8d7db",
       "style": "IPY_MODEL_61f94558aa2742a2a3fb213a24adebab",
       "value": "Map: 100%"
      }
     },
     "554394a61189405ca3edb3b767e19592": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "555399d0e67e40cca8b69341290a434d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3b15266bb8284ab08ae35c0465f27d78",
       "style": "IPY_MODEL_602277db52804760b93506e0be1c5bab",
       "value": "Map: 100%"
      }
     },
     "55a7116f3c9f41b2b2370f5af42b25c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_554394a61189405ca3edb3b767e19592",
       "style": "IPY_MODEL_fff667d8a5874e1bbc693fa029fb5c4c",
       "value": " 128/128 [00:01&lt;00:00, 106.69 examples/s]"
      }
     },
     "569018a97fa74a429df43beaaabb812e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5e275b7fd7054499b5a00fc21deee91d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "602277db52804760b93506e0be1c5bab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "615889f560ec4ca7a337665267bcba8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "61f94558aa2742a2a3fb213a24adebab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "630b7594d37743d0af78f060af96891e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d52da5826cea4b7eaa9ab6358e450118",
        "IPY_MODEL_804f1a2800094a45b3d9059c7bff3299",
        "IPY_MODEL_07c43f7c3dda454db945282137b6955e"
       ],
       "layout": "IPY_MODEL_615889f560ec4ca7a337665267bcba8c"
      }
     },
     "6361bf1073a844808b4ee93e1aa28bdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_dc0ab4ed7e584329a2eda31ee4e2bb7f",
       "style": "IPY_MODEL_06fb79eaedd542f5999cfa567dc1c0c8"
      }
     },
     "63b7a47542d34c1899b515eddcaaf23c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "697fd7a81c534176934ecbb1bab6aea4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "69aa7eb736d94844ac2cb274ca6710cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6adc57ef1f594aaa91945c64a11d62cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "714103c52ec946ed90402f2b4b8bea0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "72613281e0454d8cbed666ce1a729a21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9963e041aaba4efa88e605d2015b087f",
        "IPY_MODEL_8eb8425195224d1da095990369d40b62",
        "IPY_MODEL_24bf1e465f394cd49c67b90a59f5f8ea"
       ],
       "layout": "IPY_MODEL_b5c870a79122490d9b3231074fe86b43"
      }
     },
     "7617098b901a4c8b82acac76734f88cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7adb3853e5944a2a8eb2fd34f2f3a479": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_dd54aa09db66466297b36b8c21b36235",
       "style": "IPY_MODEL_5e275b7fd7054499b5a00fc21deee91d",
       "value": "Map: 100%"
      }
     },
     "7ae98f58290c411dbb869e72c872d462": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d07ec0d8b08741f0b381b75b613c4db1",
       "style": "IPY_MODEL_23423d1863f14371aeb763cd5b918120",
       "value": "Map: 100%"
      }
     },
     "7c4bf205ff8e4b528e65b0d9c0b3e3f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7d434cc4803140e1b88f75fd33d41aa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_b7f3c11c882d4d59af310e991ab83858",
       "max": 1406,
       "style": "IPY_MODEL_8557dd1e6c9848568150a61684f07db2",
       "value": 11
      }
     },
     "7e7dc9ade9f845f68ee1a766a5c8d7aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "804f1a2800094a45b3d9059c7bff3299": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6adc57ef1f594aaa91945c64a11d62cb",
       "max": 128,
       "style": "IPY_MODEL_160ef709d89d4432a9e636cb96c31b93",
       "value": 128
      }
     },
     "8557dd1e6c9848568150a61684f07db2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "88e8392d1c3d4283a0a240299206a2fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6361bf1073a844808b4ee93e1aa28bdf",
        "IPY_MODEL_9e6bfa5dceab436bb62357cbd8cad4ec"
       ],
       "layout": "IPY_MODEL_e8b682454d414d03ae0e605d57518a33"
      }
     },
     "89778ed8510748b89c649ed5fdd2cb52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8c08c27b60c8441caa1f142b9b0f5249": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_12db03965c26447fa8eda1a68bba2479",
       "style": "IPY_MODEL_afb34d736f89404fa3617ec9ef6d0f97",
       "value": " 128/128 [00:01&lt;00:00, 100.67 examples/s]"
      }
     },
     "8c540762e8ca4828a5db5346ffb16ba7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39b82e0a0882436a9e4302aec036d8a9",
       "style": "IPY_MODEL_40cb9b36f03e40c08caa687de04d2ab4",
       "value": "Map: 100%"
      }
     },
     "8eb8425195224d1da095990369d40b62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f364a73d6188473ab5d398ed4a63ed1a",
       "max": 128,
       "style": "IPY_MODEL_f45f60b8167d40f0aed6be4c8b318f11",
       "value": 128
      }
     },
     "917859aec4a64f55ab05ede560c8d7db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9963e041aaba4efa88e605d2015b087f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_569018a97fa74a429df43beaaabb812e",
       "style": "IPY_MODEL_10454f3f548044a38b93cd87f33de5b3",
       "value": "Map: 100%"
      }
     },
     "9bbf3dd351a449d6bcd4d491c740f2e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9e6bfa5dceab436bb62357cbd8cad4ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_394efdce51744e13b6d2828b280f5c3c",
       "max": 1,
       "style": "IPY_MODEL_fbeb43fbcd8740dbbba19002bf062667"
      }
     },
     "9f4bbd7d49094f1786792a29e82a3a1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a18a1c895e204077b726973b0d6f6af8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a357cd829c9e4459b3a388bab37cfea5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a762ff4e5f984156ae84c74b0c69259f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e69877c43271411889e9a69139684c67",
       "style": "IPY_MODEL_efc1d0ab9a6c42d99c762b2cabf3d46e",
       "value": " 128/128 [00:02&lt;00:00, 82.69 examples/s]"
      }
     },
     "a8342c5f08d54af096065721ff943165": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a8a88138421640098599df34289f3dbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_120ff4ba880241a3bf54b45bbbc608c4",
       "max": 128,
       "style": "IPY_MODEL_7e7dc9ade9f845f68ee1a766a5c8d7aa",
       "value": 128
      }
     },
     "aec4f986c470429ea7ac919821ef307e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "afb34d736f89404fa3617ec9ef6d0f97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b0885e42995d4c3fa90abe0c52be3f68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b90125a84ff343c6934da0cbb93ffffe",
       "style": "IPY_MODEL_9bbf3dd351a449d6bcd4d491c740f2e2",
       "value": " 128/128 [00:01&lt;00:00, 85.69 examples/s]"
      }
     },
     "b18c608833ab438ab48c567ccb36ea05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_41cc1ba4704e409688674182b17e9b22",
       "max": 128,
       "style": "IPY_MODEL_21b649a772e14288b6e4b6036d717649",
       "value": 128
      }
     },
     "b5c870a79122490d9b3231074fe86b43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b60964fa17cd4a138e095ab8f16bc451": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b6bc0018c4d84a3d9f32ccb21e7cae07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b7f3c11c882d4d59af310e991ab83858": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b90125a84ff343c6934da0cbb93ffffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bc8d06e3de6a44c48507621d7ba24494": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_3e1a154666314b9399721d8952adfcd6",
        "IPY_MODEL_b18c608833ab438ab48c567ccb36ea05",
        "IPY_MODEL_b0885e42995d4c3fa90abe0c52be3f68"
       ],
       "layout": "IPY_MODEL_23bae0161d64463b9d012541c3c9b20a"
      }
     },
     "be92955980a54daf881005f297b38db8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bffb03f614e84faaaecb7f43e4fc94f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_034248d93c724da98b492f23696f004d",
        "IPY_MODEL_a8a88138421640098599df34289f3dbe",
        "IPY_MODEL_c87f3f624af8488eb9ed77b7edc1880e"
       ],
       "layout": "IPY_MODEL_a8342c5f08d54af096065721ff943165"
      }
     },
     "c09f3cf15b76434da0a2df8e8bc59b58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c53a27d0baed42d9be4193d737abcb23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c87f3f624af8488eb9ed77b7edc1880e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b6bc0018c4d84a3d9f32ccb21e7cae07",
       "style": "IPY_MODEL_7c4bf205ff8e4b528e65b0d9c0b3e3f8",
       "value": " 128/128 [00:01&lt;00:00, 75.79 examples/s]"
      }
     },
     "c8c1e8910b5945758e4b4690b006c7c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2fc542818b684c57b999ce4bba15902d",
       "max": 128,
       "style": "IPY_MODEL_e033acd08e0f4f219edff0fc1f01c883",
       "value": 128
      }
     },
     "cc8806af10c34698b0e151752dbea9be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d07ec0d8b08741f0b381b75b613c4db1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d1e5e029624b45f39b4a3a7e1d8c97c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d52da5826cea4b7eaa9ab6358e450118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4200baa8f98544df9099f6299ba94760",
       "style": "IPY_MODEL_f847b2a36b064820b66bd52aa480f417",
       "value": "Map: 100%"
      }
     },
     "d7c7b911cc464a99980fc787fb04d0f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_7adb3853e5944a2a8eb2fd34f2f3a479",
        "IPY_MODEL_339178664a554eacb8679a4fb73583aa",
        "IPY_MODEL_1fc145cee352441fab2a53dca110a099"
       ],
       "layout": "IPY_MODEL_f51569a661b14026ba0bd74e269ce2a6"
      }
     },
     "d8feacb594104eceab7f006dd7b5f455": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dc0ab4ed7e584329a2eda31ee4e2bb7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dd54aa09db66466297b36b8c21b36235": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dfca09d1256e4b0896deefa87d946cb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e033acd08e0f4f219edff0fc1f01c883": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e3d89def077d47ec9c87d23747da693c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e68b085c599f4115b01e71b0266d5ac2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e69877c43271411889e9a69139684c67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e8b682454d414d03ae0e605d57518a33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eb468119ed2e4729812d31e1af1e0767": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fd59920bb81f4aa2a3bc143023fc37f3",
        "IPY_MODEL_7d434cc4803140e1b88f75fd33d41aa8",
        "IPY_MODEL_366fc6f1c3614cec8941cb49d9aed872"
       ],
       "layout": "IPY_MODEL_298a7ea0a1e54e3ea7e54dfccba227a4"
      }
     },
     "ec1a43e481a0461895189cad09ed1643": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "ef7255e151cc49e5a569a801f925ef98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "efc1d0ab9a6c42d99c762b2cabf3d46e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f364a73d6188473ab5d398ed4a63ed1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f3900afec7f3412e9a32a5e1a0159cf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f45f60b8167d40f0aed6be4c8b318f11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f51569a661b14026ba0bd74e269ce2a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5559769f8144db1930c873fb955c0b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f69eacdc16b34ec79e8194cfcce639ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f847b2a36b064820b66bd52aa480f417": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f8dc05ae8d8547e68e9b386d1867ce80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fbeb43fbcd8740dbbba19002bf062667": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fd59920bb81f4aa2a3bc143023fc37f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_19a732e7382c4341bb3d0146035ad15b",
       "style": "IPY_MODEL_a18a1c895e204077b726973b0d6f6af8",
       "value": "Epoch 0:   1%"
      }
     },
     "fd7c6787e1274899ba35fc4e9de188c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fff667d8a5874e1bbc693fa029fb5c4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
